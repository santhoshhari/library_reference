{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/Write from Files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General syntactical guideline:**\n",
    "- **Read:** `pd.read_format`\n",
    "- **Write:** `df.to_format`\n",
    "\n",
    "**Raw Files**\n",
    "\n",
    "- `pd.read_csv()`\n",
    "    - Required Argument - File name relative/absolute including path\n",
    "    - Optional Arguments\n",
    "        - **sep or delimeter - column delimiter**\n",
    "        - **dtype - dict of column to type**\n",
    "        - **low_memory - boolean (results in lower memory use while parsing)**\n",
    "        - names - list of column names\n",
    "        - index_col - Columns to use as row labels (column number or sequence)\n",
    "        - nrows - number of lines to read (incase of large files)\n",
    "        - na_values - additional strings to identify NAs (can be dict column to na string)\n",
    "        - na_filter - boolean (detect missing values)\n",
    "        - parse_dates - boolean or list of columns **(May throw memory errors for large datasets, instead ust `pd.to_datetime` after loading)**\n",
    "        - skiprows - rows to skip, can be a lambda function as well\n",
    "        - skipfooter - number of rows to skip at the end\n",
    "        - prefix - prefix to add to column numbers when no header available\n",
    "        - decimal - character to use as decimal seperator\n",
    "        - thousands - thousands seperator (default None)\n",
    "        - compression - 'infer' file compression or file compression type specifier\n",
    "        \n",
    "    - **`pd.read_table()`** is same as read_csv with tab as default delimiter \n",
    "    \n",
    "\n",
    "- `pd.to_csv()`\n",
    "    - Required Argument - None\n",
    "    - Optional Arguments\n",
    "        - **path - File name relative/absolute including path** (prints to console if none provided)\n",
    "        - **sep - column delimiter**\n",
    "        - **na_rep - how to represent NAs, default is blank**\n",
    "        - header - flag to include header in the output\n",
    "        - index - flag to include index in the output\n",
    "        - compression/decimal - same as read\n",
    "    \n",
    "    \n",
    "- `pd.read_excel()`\n",
    "    - Requird Argument - File name including path\n",
    "    - Important Optional Argument\n",
    "        - **sheet_name - integer/string or list of integers/strings with name of sheets to import**\n",
    "\n",
    "\n",
    "**Binary Formats**\n",
    "\n",
    "- `pd.read_feather()`\n",
    "    - Most efficient way of reading and writing columnar data\n",
    "    - Required Argument - File path\n",
    "    - Optional Argument - nthreads (# of CPUs to use while reading)\n",
    "\n",
    "\n",
    "- `pd.read_pickle()`\n",
    "    - Required Argument - File path\n",
    "    - Optional Argument - compression\n",
    "    \n",
    "\n",
    "- `pd.read_parquet()`\n",
    "    - Required Argument - File path\n",
    "    - Aside - Parquet format lacks built in support for categorical data. Optimized for IO constrained scan-oriented use cases.\n",
    "\n",
    "\n",
    "**SQL**\n",
    "- `pd.read_sql()`\n",
    "    - Required Arguments - Query and connection object\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Parsable Formats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- JSON (`read_json`, `to_json`)\n",
    "- HTML (`read_html`, `to_html`)\n",
    "- Clipboard (`read_clipboard`, `to_clipboard`)\n",
    "- HDF5 (hierarchical data, `read_hdf`, `to_hdf`)\n",
    "- MessagePack (`read_msgpack`, `to_msgpack`)\n",
    "- stata (`read_stata`, `to_stata`)\n",
    "- SAS (`read_sas`, write not available)\n",
    "- Google Big Query (`read_gbq`, `to_gbq`)\n",
    "\n",
    "Detailed Documentation: https://pandas.pydata.org/pandas-docs/stable/io.html\n",
    "\n",
    "Performance comparison of I/O on various formats: https://pandas.pydata.org/pandas-docs/stable/io.html#io-perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame from Lists/Dictionaries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.DataFrame(object, index, columns, dtype)`\n",
    "\n",
    "**From Dictionary:** keys read as columns and values as rows\n",
    "\n",
    "**From List:**\n",
    "- Elemets of list are rows `[[a,b,c],[1,2,3]]` will be read as \n",
    "    \n",
    "|**0**|**1**|**2**|\n",
    "|-----|-----|-----|\n",
    "|  a  |  b  |  c  |\n",
    "|  1  |  2  |  3  |\n",
    "\n",
    "- Elemets of list are columns `[[a,b,c],[1,2,3]]` then use `pd.DataFrame(obj).transpose()`\n",
    "\n",
    "|**0**|**1**|\n",
    "|-----|-----|\n",
    "|  a  |  1  |\n",
    "|  b  |  2  |\n",
    "|  c  |  3  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Casting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.dtypes` - Get datatypes of all columns\n",
    "- `df.col.astype('dtype')` - Explicitly convert `col` to type `dtype`\n",
    "- `df[[cols]].astype('dtype')` - Explicitly convert subset of columns (`cols`) to type `dtype`\n",
    "- `df.astype({'a': 'dtype1' , 'b': 'dtype2'})` - Specify data type for each column\n",
    "- Use `copy=False` argument (instead of inplace) for updating without creating a copy\n",
    "\n",
    "**For one dimensional objects (series)**, use `pd.to_numeric()`, `pd.to_datetime()`, `pd.to_timedelta()` for type casting. Handy arguments:\n",
    "- `errors`: `raise` to throw error, `coerce` to replace with NaNs, `ignore` to copy the value as is without type conversion\n",
    "- `downcast`: downcasting the newly (or already) numeric data to a smaller dtype, conserving memory. Can take values `integer`, `signed`, `unsigned`, `float`\n",
    "\n",
    "**Commonly used data types:**\n",
    "- `object`\n",
    "- `category`\n",
    "- `float<x>` - x can be 16, 32, 64 (default)\n",
    "- `int<x>` - x can be 8, 16, 32, 64 (default)\n",
    "- `uint<x>` - x can be 8, 16, 32, 64 (default)\n",
    "- `bool`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Data type**|**Range of Values**|\n",
    "|------|------|\n",
    "| int8 | -128 to 127 |\n",
    "| int16 | -32,768 to 32,767 |\n",
    "| int32 | -2,147,483,648 to 2,147,483,647 |\n",
    "| int64 | -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 |\n",
    "| uint8 | 0 to 255 |\n",
    "| uint16 | 0 to 65,535 |\n",
    "| uint32 | 0 to 4,294,967,295 |\n",
    "| uint64 | 0 to 18,446,744,073,709,551,615 |\n",
    "\n",
    "|**Data type**|**Resolution**|\n",
    "|------|------|\n",
    "| float16 | 1e-3 |\n",
    "| float32 | 1e-6 |\n",
    "| float64 | 1e-15 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T03:00:37.509520Z",
     "start_time": "2018-04-17T03:00:37.504919Z"
    }
   },
   "source": [
    "**Get info about data types**\n",
    "- `np.finfo(np.float16)`\n",
    "- `np.iinfo(np.int16)`\n",
    "\n",
    "**Columns can get potentially upcasted when combined with other types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set index `df.set_index(keys, drop=True, append=False, inplace=False)`\n",
    "    - `keys` - column or list of columns to set as index\n",
    "    - `drop` - Flag to drop columns listed as keys\n",
    "    - `append` - Append index to existing index\n",
    "- `df.reset_index(drop=False)` -  transfers the index values into the DataFrameâ€™s columns and sets a simple integer index\n",
    "    - `drop` - Flag to drop index instead of converting to columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Access and Filtering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index or label based:**\n",
    "- `df.iloc[1:2,3:4]` - Select data based on integer location\n",
    "- `df.loc[1:2,'a':'c']` or `df.loc[1:2,['a','b','c']]` - Select data based on row/column labels. By default row labels are row indexes and hence the similarity between first element of `iloc` and `loc`.\n",
    "    - **Important Note: Slice selected will be inclusive of both indexes specified, unlike elsewhere in python (`loc[1:2]` returns two rows).**\n",
    "    - Second element of loc can either be a list or from_col:to_col\n",
    "- **Note:** Indixing with [ ] has slight overhead from figuring out if you're asking for single-label access, slicing, boolean indexing. If you only want to access a scalar value, the fastest way is to use the `at` and `iat` methods\n",
    "    - `df.at[dates[5], 'A']`\n",
    "    - `df.iat[3, 0]`\n",
    "    \n",
    "\n",
    "**Filter:**\n",
    "- `df.select_dtypes(include=[], exclude=[])` - Select columns based on dtypes; Exclude/Include should not have overlap\n",
    "- `df[boolean_array]` - length of boolean array must be same as # of rows in data frame. Boolean array can be derived from single or multiple conditions. Examples:\n",
    "    - `df[df.col1==\"x\"]`\n",
    "    - `df[cond1 operator cond2]`\n",
    "    - Operators:\n",
    "        - `|` or `or` (throws ambiguity error with multiple conditions)\n",
    "        - `&` or `and` (throws ambiguity error with multiple conditions)\n",
    "        - `~` (not operator)\n",
    "        - `==` equality\n",
    "        - `!=` inequality\n",
    "        - `isin(list)` equivalent to `in` in SQL\n",
    "        - `>=`, `<=` relational\n",
    "        - `all(axis=0)` checks if all values across rows in each column are True\n",
    "        - `any(axis=1)` checks if atleast one value across columns in each row are True\n",
    "\n",
    "- `df.query(condition)` - condition can be involving columns or constants. Example - `(col1 > col2)` or `(col1 == 10)`\n",
    "- `df.filter()` - Arguments (optional but atleast 1 of first 3 required)\n",
    "    - `items` - list of column or row labels\n",
    "    - `like` - string for partial match (case sensitive)\n",
    "    - `regex` - string with regex to parse\n",
    "    - `axis` - row(0)/column(1) labels to filter \n",
    "- `df.where()` - Returns dataframe of same shape\n",
    "- `df.isnull()` - checks if individual elements of dataframe are null (NaN/NaT)\n",
    "- `df.notnull()` - checks if individual elements of dataframe are not null (NaN/NaT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.fillna(value, inplace=True)` - Fills NaNs in all columns with value\n",
    "- `df.col.fillna(value, inplace=True)` - Fills NaNs in column `col` with value\n",
    "- `df[[cols]] = df[[cols]].fillna(value)` - Fills NaNs in columns `cols` with value\n",
    "- `df.dropna(axis=0, how='any', inplace=True)` - Drops rows with NaNs in any of the columns; For columns, use `axis=1`\n",
    "- `df.dropna(subset=[cols])` - Drops rows with NaNs in any of columns in `cols`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with duplicate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.drop_duplicates()` drop duplicate columns from the dataframe. Arguments\n",
    "    - `subset` - Subset of columns to be considered for identifying duplicates. Default all columns\n",
    "    - `keep` - Can take `'first'`, `'last'` or `False` implying first, last or no occurance of the duplicate record will be retained respectively\n",
    "    - `inplace`\n",
    "    \n",
    "- `df.col.unique()` get unique values of a column/series **(can not be applied on dataframe)**\n",
    "- `df.duplicated()` returns true if the row is duplicate of any of the previous rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply and Map:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.apply(func, axis=0)`\n",
    "\n",
    "- `func` - function to apply on df rows/columns\n",
    "- `axis` - can take 0/index or 1/columns\n",
    "    - 0/index - apply function to each column\n",
    "    - 1/columns - apply function to each row\n",
    "- **Note:** Checkout swiftapply from swifter package for multi-threaded apply (uses dask under the hood)\n",
    "\n",
    "`df.applymap(func)` - for elementwise application of function (ex: rounding floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Denormalizing Data (Pivot/Melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalize/Unpivot (wide to long format) `pd.melt(df, id_vars, val_vars, var_name, val_name, col_level)`\n",
    "    - `df` - dataframe to melt\n",
    "    - `id_vars` - pivot column/columns\n",
    "    - `val_vars` - column/s to convert as rows\n",
    "    - `var_name` - name of variable column in output dataframe\n",
    "    - `val_name` - name of value column in output dataframe\n",
    "    - `col_level` - Used for multiindex columns (Level as integer or columns list)\n",
    "\n",
    "\n",
    "- Denormalize/Pivot (long to wide format) `df.pivot_table(values, index, columns)` or `pd.pivot_table(df, v,i,c)`\n",
    "    - `values` - Column to aggregate\n",
    "    - `index` - Keys to groupby in the pivot table index (rows)\n",
    "    - `columns` - Keys to groupby on the pivot table columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy like broadcasting behavior can be obtained by using following functions:\n",
    "\n",
    "- `df.add(row, axis=1)` - adds row to all rows of the dataframe df \n",
    "- `df.sub(column, axis=0)` - Subtracts column from all columns of the dataframe df\n",
    "- `df.mul()` - multiply\n",
    "- `df.div()` - divide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.groupby(by=['col1','col2']).func()` - func can be `sum`, `mean`, `count`, `unique`, `nunique`\n",
    "- `df.groupby(by=['col1','col2']).aggregate({'col3':['sum'], 'col4':['mean','count'], 'col5': lambda x: sum(x)/len(x)})`\n",
    "- `df.groupby(by=['col1','col2']).transform(lambda x: sum(x))` - Apply custom function to all columns\n",
    "\n",
    "**Note:** Aggregate method usually returns data frame with **multiindex columns**. Explicitly update column names afetr the aggregation. It is also advised to `reset_index` to re-index the resulting dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.concat(objs, axis, ignore_index=False)` - concatenate rows/columns\n",
    "- `objs` - sequence of dataframes (list)\n",
    "- `axis` - axis to concatenate along\n",
    "- `ignore_index` - If True, do not use the index values along the concatenation axis. The resulting axis will be labeled 0, ..., n - 1. Useful when index of axis has no meaning\n",
    "\n",
    "`df.append(other, ignore_index=False)` - concatenate rows\n",
    "- `other` - dataframe or series or dict\n",
    "- `ignore_index` - same as that of concatenate\n",
    "\n",
    "**Note:** It is worth noting however, that concat (and therefore append) makes a full copy of the data, and that constantly reusing this function can create a significant performance hit. If you need to use the operation over several datasets, use a list comprehension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.merge(right, how, on, left_on, right_on, left_index, right_index, suffixes)`\n",
    "\n",
    "- `right` - Dataframe\n",
    "- `how` -  join type (available - 'left', 'right', 'outer', 'inner'), default 'inner'\n",
    "- `on` - Field names to join on (label or list) and must be found in both DataFrames\n",
    "- `left_on` - Field names to join on in left DataFrame\n",
    "- `right_on` - Field names to join on in right DataFrame\n",
    "- `left_index` - boolean, Use the index from the left DataFrame as the join key(s).\n",
    "- `right_index` - boolean, Use the index from the right DataFrame as the join key(s).\n",
    "- `suffixes` : 2-length sequence (tuple, list) Suffix to apply to overlapping column names in the left and right\n",
    "    side, respectively\n",
    "\n",
    "**Note:**\n",
    "- `df.join` also available but always use merge\n",
    "- Pandas supports high performance in-memory join operations idiomatically very similar to relational databases like SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.plot(x=None, y=None, kind='line')` wrapper around matplotlib's plt.plot()\n",
    "- `kind`\n",
    "    - 'line' : line plot (default)\n",
    "    - 'bar' : vertical bar plot\n",
    "    - 'barh' : horizontal bar plot\n",
    "    - 'hist' : histogram\n",
    "    - 'box' : boxplot\n",
    "    - 'kde' : Kernel Density Estimation plot\n",
    "    - 'density' : same as 'kde'\n",
    "    - 'area' : area plot\n",
    "    - 'pie' : pie plot\n",
    "    - 'scatter' : scatter plot\n",
    "    - 'hexbin' : hexbin plot\n",
    "\n",
    "- `df.plot.kind()` same functionality as above\n",
    "    - `stacked` - Flag for stacking bars\n",
    "    - `alpha` - Transparency\n",
    "    - `bins` - Bin count for histogram\n",
    "    - `orientation` - For histogram - 'horizontal'\n",
    "    - `cumulative` - For histogram - True/False\n",
    "\n",
    " \n",
    "Detailed visualization examples available at https://pandas.pydata.org/pandas-docs/stable/visualization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handy Utilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.shape` - Get the dimensions of the dataframe\n",
    "- `df.values` - Get the values as a numpy array\n",
    "- `df.head(x)` - Get first x rows of the dataframe\n",
    "- `df.tail(x)` - Get last x rows of the dataframe\n",
    "- `df.columns()` - Get column names\n",
    "- `df.T` - Transpose dataframe\n",
    "- `df.rename(columns=dict)` - Rename columns from key (existing column name) to value (renamed name) in the dict\n",
    "    - `df.rename(mapper=str.lower)` mapper function to lower column names. Equivalent to below command\n",
    "    - `df.columns = df.columns.str.lower()` Converting column names to lower case\n",
    "- `df.col.unique()` - Get unique values in a column\n",
    "- `df.duplicated()` - Returns True for duplicated records, flags duplicate records similar to `df.drop_duplicates()`\n",
    "- `df.info()` - High level metadata of columns and data\n",
    "- `df.nunique()` - Number of unique records in each column\n",
    "- `df.describe()` - High level statistical summary of numerical columns\n",
    "- `pd.get_dummies()` - **OHE**\n",
    "- Pandas sees benifits of operations like aggregation, joins on sorted columns similar to tables in relational DBs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
