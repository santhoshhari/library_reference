{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/Write from Files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General syntactical guideline:**\n",
    "- **Read:** `pd.read_format`\n",
    "- **Write:** `df.to_format`\n",
    "\n",
    "**Raw Files**\n",
    "\n",
    "- `pd.read_csv()`\n",
    "    - Required Argument - File name relative/absolute including path\n",
    "    - Optional Arguments\n",
    "        - **sep or delimeter - column delimiter**\n",
    "        - **dtype - dict of column to type**\n",
    "        - **low_memory - boolean (results in lower memory use while parsing)**\n",
    "        - names - list of column names\n",
    "        - index_col - Columns to use as row labels (column number or sequence)\n",
    "        - nrows - number of lines to read (incase of large files)\n",
    "        - na_values - additional strings to identify NAs (can be dict column to na string)\n",
    "        - na_filter - boolean (detect missing values)\n",
    "        - parse_dates - boolean or list of columns **(May throw memory errors for large datasets, instead ust `pd.to_datetime` after loading)**\n",
    "        - skiprows - rows to skip, can be a lambda function as well\n",
    "        - skipfooter - number of rows to skip at the end\n",
    "        - prefix - prefix to add to column numbers when no header available\n",
    "        - decimal - character to use as decimal seperator\n",
    "        - thousands - thousands seperator (default None)\n",
    "        - compression - 'infer' file compression or file compression type specifier\n",
    "        \n",
    "    - **`pd.read_table()`** is same as read_csv with tab as default delimiter \n",
    "    \n",
    "\n",
    "- `pd.to_csv()`\n",
    "    - Required Argument - None\n",
    "    - Optional Arguments\n",
    "        - **path - File name relative/absolute including path** (prints to console if none provided)\n",
    "        - **sep - column delimiter**\n",
    "        - **na_rep - how to represent NAs, default is blank**\n",
    "        - header - flag to include header in the output\n",
    "        - index - flag to include index in the output\n",
    "        - compression/decimal - same as read\n",
    "    \n",
    "    \n",
    "- `pd.read_excel()`\n",
    "    - Requird Argument - File name including path\n",
    "    - Important Optional Argument\n",
    "        - **sheet_name - integer/string or list of integers/strings with name of sheets to import**\n",
    "\n",
    "\n",
    "**Binary Formats**\n",
    "\n",
    "- `pd.read_feather()`\n",
    "    - Most efficient way of reading and writing columnar data\n",
    "    - Required Argument - File path\n",
    "    - Optional Argument - nthreads (# of CPUs to use while reading)\n",
    "\n",
    "\n",
    "- `pd.read_pickle()`\n",
    "    - Required Argument - File path\n",
    "    - Optional Argument - compression\n",
    "    \n",
    "\n",
    "- `pd.read_parquet()`\n",
    "    - Required Argument - File path\n",
    "    - Aside - Parquet format lacks built in support for categorical data. Optimized for IO constrained scan-oriented use cases.\n",
    "\n",
    "\n",
    "**SQL**\n",
    "- `pd.read_sql()`\n",
    "    - Required Arguments - Query and connection object\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Parsable Formats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- JSON (`read_json`, `to_json`)\n",
    "- HTML (`read_html`, `to_html`)\n",
    "- Clipboard (`read_clipboard`, `to_clipboard`)\n",
    "- HDF5 (hierarchical data, `read_hdf`, `to_hdf`)\n",
    "- MessagePack (`read_msgpack`, `to_msgpack`)\n",
    "- stata (`read_stata`, `to_stata`)\n",
    "- SAS (`read_sas`, write not available)\n",
    "- Google Big Query (`read_gbq`, `to_gbq`)\n",
    "\n",
    "Detailed Documentation: https://pandas.pydata.org/pandas-docs/stable/io.html\n",
    "\n",
    "Performance comparison of I/O on various formats: https://pandas.pydata.org/pandas-docs/stable/io.html#io-perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame from Lists/Dictionaries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.DataFrame(object, index, columns, dtype)`\n",
    "\n",
    "**From Dictionary:** keys read as columns and values as rows\n",
    "\n",
    "**From List:**\n",
    "- Elemets of list are rows `[[a,b,c],[1,2,3]]` will be read as \n",
    "    \n",
    "|**0**|**1**|**2**|\n",
    "|-----|-----|-----|\n",
    "|  a  |  b  |  c  |\n",
    "|  1  |  2  |  3  |\n",
    "\n",
    "- Elemets of list are columns `[[a,b,c],[1,2,3]]` then use `pd.DataFrame(obj).transpose()`\n",
    "\n",
    "|**0**|**1**|\n",
    "|-----|-----|\n",
    "|  a  |  1  |\n",
    "|  b  |  2  |\n",
    "|  c  |  3  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Casting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.dtypes` - Get datatypes of all columns\n",
    "- `df.col.astype('dtype')` - Explicitly convert `col` to type `dtype`\n",
    "- `df[[cols]].astype('dtype')` - Explicitly convert subset of columns (`cols`) to type `dtype`\n",
    "- `df.astype({'a': 'dtype1' , 'b': 'dtype2'})` - Specify data type for each column\n",
    "- Use `copy=False` argument (instead of inplace) for updating without creating a copy\n",
    "\n",
    "**For one dimensional objects (series)**, use `pd.to_numeric()`, `pd.to_datetime()`, `pd.to_timedelta()` for type casting. Handy arguments:\n",
    "- `errors`: `raise` to throw error, `coerce` to replace with NaNs, `ignore` to copy the value as is without type conversion\n",
    "- `downcast`: downcasting the newly (or already) numeric data to a smaller dtype, conserving memory. Can take values `integer`, `signed`, `unsigned`, `float`\n",
    "\n",
    "**Commonly used data types:**\n",
    "- `object`\n",
    "- `category`\n",
    "- `float<x>` - x can be 16, 32, 64 (default)\n",
    "- `int<x>` - x can be 8, 16, 32, 64 (default)\n",
    "- `uint<x>` - x can be 8, 16, 32, 64 (default)\n",
    "- `bool`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Data type**|**Range of Values**|\n",
    "|------|------|\n",
    "| int8 | -128 to 127 |\n",
    "| int16 | -32,768 to 32,767 |\n",
    "| int32 | -2,147,483,648 to 2,147,483,647 |\n",
    "| int64 | -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 |\n",
    "| uint8 | 0 to 255 |\n",
    "| uint16 | 0 to 65,535 |\n",
    "| uint32 | 0 to 4,294,967,295 |\n",
    "| uint64 | 0 to 18,446,744,073,709,551,615 |\n",
    "\n",
    "|**Data type**|**Resolution**|\n",
    "|------|------|\n",
    "| float16 | 1e-3 |\n",
    "| float32 | 1e-6 |\n",
    "| float64 | 1e-15 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T03:00:37.509520Z",
     "start_time": "2018-04-17T03:00:37.504919Z"
    }
   },
   "source": [
    "**Get info about data types**\n",
    "- `np.finfo(np.float16)`\n",
    "- `np.iinfo(np.int16)`\n",
    "\n",
    "**Columns can get potentially upcasted when combined with other types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Access and Filtering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index or label based:**\n",
    "- `df.iloc[1:2,3:4]` - Select data based on integer location\n",
    "- `df.loc[1:2,'a':'c']` or `df.loc[1:2,['a','b','c']]` - Select data based on row/column labels. By default row labels are row indexes and hence the similarity between first element of `iloc` and `loc`.\n",
    "    - **Important Note: Slice selected will be inclusive of both indexes specified, unlike elsewhere in python (`loc[1:2]` returns two rows).**\n",
    "    - Second element of loc can either be a list or from_col:to_col\n",
    "    \n",
    "\n",
    "**Filter:**\n",
    "- `df.select_dtypes(include=[], exclude=[])` - Select columns based on dtypes; Exclude/Include should not have overlap\n",
    "- `df[boolean_array]` - length of boolean array must be same as # of rows in data frame. Boolean array can be derived from single or multiple conditions. Examples:\n",
    "    - `df[df.col1==\"x\"]`\n",
    "    - `df[cond1 operator cond2]`\n",
    "    - Operators:\n",
    "        - `|` or `or` (throws ambiguity error with multiple conditions)\n",
    "        - `&` or `and` (throws ambiguity error with multiple conditions)\n",
    "        - `~` (not operator)\n",
    "        - `==` equality\n",
    "        - `!=` inequality\n",
    "        - `isin(list)` equivalent to `in` in SQL\n",
    "        - `>=`, `<=` relational\n",
    "        - `all(axis=0)` checks if all values across rows in each column are True\n",
    "        - `any(axis=1)` checks if atleast one value across columns in each row are True\n",
    "\n",
    "- `df.query(condition)` - condition can be involving columns or constants. Example - `(col1 > col2)` or `(col1 == 10)`\n",
    "- `df.filter()` - Arguments (optional but atleast 1 of first 3 required)\n",
    "    - `items` - list of column or row labels\n",
    "    - `like` - string for partial match (case sensitive)\n",
    "    - `regex` - string with regex to parse\n",
    "    - `axis` - row(0)/column(1) labels to filter \n",
    "- `df.isnull()` - checks if individual elements of dataframe are null (NaN/NaT)\n",
    "- `df.notnull()` - checks if individual elements of dataframe are not null (NaN/NaT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.fillna(value, inplace=True)` - Fills NaNs in all columns with value\n",
    "- `df.col.fillna(value, inplace=True)` - Fills NaNs in column `col` with value\n",
    "- `df[[cols]] = df[[cols]].fillna(value)` - Fills NaNs in columns `cols` with value\n",
    "- `df.dropna(axis=0, how='any', inplace=True)` - Drops rows with NaNs in any of the columns; For columns, use `axis=1`\n",
    "- `df.dropna(subset=[cols])` - Drops rows with NaNs in any of columns in `cols`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with duplicate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.drop_duplicates()` drop duplicate columns from the dataframe. Arguments\n",
    "    - `subset` - Subset of columns to be considered for identifying duplicates. Default all columns\n",
    "    - `keep` - Can take `'first'`, `'last'` or `False` implying first, last or no occurance of the duplicate record will be retained respectively\n",
    "    - `inplace`\n",
    "    \n",
    "- `df.col.unique()` get unique values of a column/series **(can not be applied on dataframe)**\n",
    "- `df.duplicated()` returns true if the row is duplicate of any of the previous rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply and Map:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.apply(func, axis=0)`\n",
    "\n",
    "- `func` - function to apply on df rows/columns\n",
    "- `axis` - can take 0/index or 1/columns\n",
    "    - 0/index - apply function to each column\n",
    "    - 1/columns - apply function to each row\n",
    "- **Note:** Checkout swiftapply from swifter package for multi-threaded apply (uses dask under the hood)\n",
    "\n",
    "`df.applymap(func)` - for elementwise application of function (ex: rounding floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Denormalizing Data (Pivot/Melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalize/Unpivot (wide to long format) `pd.melt(df, id_vars, val_vars, var_name, val_name, col_level)`\n",
    "    - `df` - dataframe to melt\n",
    "    - `id_vars` - pivot column/columns\n",
    "    - `val_vars` - column/s to convert as rows\n",
    "    - `var_name` - name of variable column in output dataframe\n",
    "    - `val_name` - name of value column in output dataframe\n",
    "    - `col_level` - Used for multiindex columns (Level as integer or columns list)\n",
    "\n",
    "\n",
    "- Denormalize/Pivot (long to wide format) `df.pivot_table(values, index, columns)` or `pd.pivot_table(df, v,i,c)`\n",
    "    - `values` - Column to aggregate\n",
    "    - `index` - Keys to groupby in the pivot table index (rows)\n",
    "    - `columns` - Keys to groupby on the pivot table columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy like broadcasting behavior can be obtained by using following functions:\n",
    "\n",
    "- `df.add(row, axis=1)` - adds row to all rows of the dataframe df \n",
    "- `df.sub(column, axis=0)` - Subtracts column from all columns of the dataframe df\n",
    "- `df.mul()` - multiply\n",
    "- `df.div()` - divide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.groupby(by=['col1','col2']).func()` - func can be `sum`, `mean`, `count`, `unique`, `nunique`\n",
    "- `df.groupby(by=['col1','col2']).aggregate({'col3':['sum'], 'col4':['mean','count'], 'col5': lambda x: sum(x)/len(x)})`\n",
    "- `df.groupby(by=['col1','col2']).transform(lambda x: sum(x))` - Apply custom function to all columns\n",
    "\n",
    "**Note:** Aggregate method usually returns data frame with **multiindex columns**. Explicitly update column names afetr the aggregation. It is also advised to `reset_index` to re-index the resulting dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** It is worth noting however, that concat (and therefore append) makes a full copy of the data, and that constantly reusing this function can create a significant performance hit. If you need to use the operation over several datasets, use a list comprehension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.merge(right, how, on, left_on, right_on, left_index, right_index, suffixes)`\n",
    "\n",
    "- `right` - Dataframe\n",
    "- `how` -  join type (available - 'left', 'right', 'outer', 'inner'), default 'inner'\n",
    "- `on` - Field names to join on (label or list) and must be found in both DataFrames\n",
    "- `left_on` - Field names to join on in left DataFrame\n",
    "- `right_on` - Field names to join on in right DataFrame\n",
    "- `left_index` - boolean, Use the index from the left DataFrame as the join key(s).\n",
    "- `right_index` - boolean, Use the index from the right DataFrame as the join key(s).\n",
    "- `suffixes` : 2-length sequence (tuple, list) Suffix to apply to overlapping column names in the left and right\n",
    "    side, respectively\n",
    "\n",
    "**Note:**\n",
    "- `df.join` also available but always use merge\n",
    "- Pandas supports high performance in-memory join operations idiomatically very similar to relational databases like SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handy Utilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.shape` - Get the dimensions of the dataframe\n",
    "- `df.values` - Get the values as a numpy array\n",
    "- `df.head(x)` - Get first x rows of the dataframe\n",
    "- `df.tail(x)` - Get last x rows of the dataframe\n",
    "- `df.columns()` - Get column names\n",
    "- `df.rename(columns=dict)` - Rename columns from key (existing column name) to value (renamed name) in the dict\n",
    "    - `df.rename(mapper=str.lower)` mapper function to lower column names. Equivalent to below command\n",
    "    - `df.columns = df.columns.str.lower()` Converting column names to lower case\n",
    "- `df.col.unique()` - Get unique values in a column\n",
    "- `df.duplicated()` - Returns True for duplicated records, flags duplicate records similar to `df.drop_duplicates()`\n",
    "- `df.info()` - High level metadata of columns and data\n",
    "- `df.nunique()` - Number of unique records in each column\n",
    "- `df.describe()` - High level statistical summary of numerical columns\n",
    "- `pd.get_dummies()` - **OHE**\n",
    "- Pandas sees benifits of operations like aggregation, joins on sorted columns similar to tables in relational DBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T20:56:27.447255Z",
     "start_time": "2018-04-28T20:56:27.438388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>large</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>large</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>small</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>small</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>large</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>small</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bar</td>\n",
       "      <td>two</td>\n",
       "      <td>small</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bar</td>\n",
       "      <td>two</td>\n",
       "      <td>large</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B      C  D\n",
       "0  foo  one  small  1\n",
       "1  foo  one  large  2\n",
       "2  foo  one  large  2\n",
       "3  foo  two  small  3\n",
       "4  foo  two  small  3\n",
       "5  bar  one  large  4\n",
       "6  bar  one  small  5\n",
       "7  bar  two  small  6\n",
       "8  bar  two  large  7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T20:57:15.072272Z",
     "start_time": "2018-04-28T20:57:15.065823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
