{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T18:31:14.886867Z",
     "start_time": "2018-04-13T18:31:14.883711Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T07:08:34.504422Z",
     "start_time": "2018-04-17T07:08:34.499073Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"a\":[1,2,3], \"b\":['a','b','c'], \"c\":[1,2,3], \"d\":[1,2,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T07:31:14.748879Z",
     "start_time": "2018-04-17T07:31:14.741974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like=\"A\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/Write from Files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General syntactical guideline:**\n",
    "- **Read:** `pd.read_format`\n",
    "- **Write:** `df.to_format`\n",
    "\n",
    "**Raw Files**\n",
    "\n",
    "- `pd.read_csv()`\n",
    "    - Required Argument - File name relative/absolute including path\n",
    "    - Optional Arguments\n",
    "        - **sep or delimeter - column delimiter**\n",
    "        - **dtype - dict of column to type**\n",
    "        - **low_memory - boolean (results in lower memory use while parsing)**\n",
    "        - names - list of column names\n",
    "        - index_col - Columns to use as row labels (column number or sequence)\n",
    "        - nrows - number of lines to read (incase of large files)\n",
    "        - na_values - additional strings to identify NAs (can be dict column to na string)\n",
    "        - na_filter - boolean (detect missing values)\n",
    "        - parse_dates - boolean or list of columns **(May throw memory errors for large datasets, instead ust `pd.to_datetime` after loading)**\n",
    "        - skiprows - rows to skip, can be a lambda function as well\n",
    "        - skipfooter - number of rows to skip at the end\n",
    "        - prefix - prefix to add to column numbers when no header available\n",
    "        - decimal - character to use as decimal seperator\n",
    "        - thousands - thousands seperator (default None)\n",
    "        - compression - 'infer' file compression or file compression type specifier\n",
    "        \n",
    "    - **`pd.read_table()`** is same as read_csv with tab as default delimiter \n",
    "    \n",
    "\n",
    "- `pd.to_csv()`\n",
    "    - Required Argument - None\n",
    "    - Optional Arguments\n",
    "        - **path - File name relative/absolute including path** (prints to console if none provided)\n",
    "        - **sep - column delimiter**\n",
    "        - **na_rep - how to represent NAs, default is blank**\n",
    "        - header - flag to include header in the output\n",
    "        - index - flag to include index in the output\n",
    "        - compression/decimal - same as read\n",
    "    \n",
    "    \n",
    "- `pd.read_excel()`\n",
    "    - Requird Argument - File name including path\n",
    "    - Important Optional Argument\n",
    "        - **sheet_name - integer/string or list of integers/strings with name of sheets to import**\n",
    "\n",
    "\n",
    "**Binary Formats**\n",
    "\n",
    "- `pd.read_feather()`\n",
    "    - Most efficient way of reading and writing columnar data\n",
    "    - Required Argument - File path\n",
    "    - Optional Argument - nthreads (# of CPUs to use while reading)\n",
    "\n",
    "\n",
    "- `pd.read_pickle()`\n",
    "    - Required Argument - File path\n",
    "    - Optional Argument - compression\n",
    "    \n",
    "\n",
    "- `pd.read_parquet()`\n",
    "    - Required Argument - File path\n",
    "    - Aside - Parquet format lacks built in support for categorical data. Optimized for IO constrained scan-oriented use cases.\n",
    "\n",
    "\n",
    "**SQL**\n",
    "- `pd.read_sql()`\n",
    "    - Required Arguments - Query and connection object\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Parsable Formats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- JSON (`read_json`, `to_json`)\n",
    "- HTML (`read_html`, `to_html`)\n",
    "- Clipboard (`read_clipboard`, `to_clipboard`)\n",
    "- HDF5 (hierarchical data, `read_hdf`, `to_hdf`)\n",
    "- MessagePack (`read_msgpack`, `to_msgpack`)\n",
    "- stata (`read_stata`, `to_stata`)\n",
    "- SAS (`read_sas`, write not available)\n",
    "- Google Big Query (`read_gbq`, `to_gbq`)\n",
    "\n",
    "Detailed Documentation: https://pandas.pydata.org/pandas-docs/stable/io.html\n",
    "\n",
    "Performance comparison of I/O on various formats: https://pandas.pydata.org/pandas-docs/stable/io.html#io-perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Casting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.dtypes` - Get datatypes of all columns\n",
    "- `df.col.astype('dtype')` - Explicitly convert `col` to type `dtype`\n",
    "- `df[[cols]].astype('dtype')` - Explicitly convert subset of columns (`cols`) to type `dtype`\n",
    "- `df.astype({'a': 'dtype1' , 'b': 'dtype2'})` - Specify data type for each column\n",
    "- Use `copy=False` argument (instead of inplace) for updating without creating a copy\n",
    "\n",
    "**For one dimensional objects (series)**, use `pd.to_numeric()`, `pd.to_datetime()`, `pd.to_timedelta()` for type casting. Handy arguments:\n",
    "- `errors`: `raise` to throw error, `coerce` to replace with NaNs, `ignore` to copy the value as is without type conversion\n",
    "- `downcast`: downcasting the newly (or already) numeric data to a smaller dtype, conserving memory. Can take values `integer`, `signed`, `unsigned`, `float`\n",
    "\n",
    "**Commonly used data types:**\n",
    "- `object`\n",
    "- `category`\n",
    "- `float<x>` - x can be 16, 32, 64 (default)\n",
    "- `int<x>` - x can be 8, 16, 32, 64 (default)\n",
    "- `uint<x>` - x can be 8, 16, 32, 64 (default)\n",
    "- `bool`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Data type**|**Range of Values**|\n",
    "|------|------|\n",
    "| int8 | -128 to 127 |\n",
    "| int16 | -32,768 to 32,767 |\n",
    "| int32 | -2,147,483,648 to 2,147,483,647 |\n",
    "| int64 | -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 |\n",
    "| uint8 | 0 to 255 |\n",
    "| uint16 | 0 to 65,535 |\n",
    "| uint32 | 0 to 4,294,967,295 |\n",
    "| uint64 | 0 to 18,446,744,073,709,551,615 |\n",
    "\n",
    "|**Data type**|**Resolution**|\n",
    "|------|------|\n",
    "| float16 | 1e-3 |\n",
    "| float32 | 1e-6 |\n",
    "| float64 | 1e-15 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T03:00:37.509520Z",
     "start_time": "2018-04-17T03:00:37.504919Z"
    }
   },
   "source": [
    "**Get info about data types**\n",
    "- `np.finfo(np.float16)`\n",
    "- `np.iinfo(np.int16)`\n",
    "\n",
    "**Columns can get potentially upcasted when combined with other types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Access and Filtering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index or label based:**\n",
    "- `df.iloc[1:2,3:4]` - Select data based on integer location\n",
    "- `df.loc[1:2,'a':'c']` or `df.loc[1:2,['a','b','c']]` - Select data based on row/column labels. By default row labels are row indexes and hence the similarity between first element of `iloc` and `loc`.\n",
    "    - **Important Note: Slice selected will be inclusive of both indexes specified, unlike elsewhere in python (`loc[1:2]` returns two rows).**\n",
    "    - Second element of loc can either be a list or from_col:to_col\n",
    "    \n",
    "\n",
    "**Filter:**\n",
    "- `df.select_dtypes(include=[], exclude=[])` - Select columns based on dtypes; Exclude/Include should not have overlap\n",
    "- `df[boolean_array]` - length of boolean array must be same as # of rows in data frame. Boolean array can be derived from single or multiple conditions. Examples:\n",
    "    - `df[df.col1==\"x\"]`\n",
    "    - `df[cond1 operator cond2]`\n",
    "    - Operators:\n",
    "        - `|` or `or` (throws ambiguity error with multiple conditions)\n",
    "        - `&` or `and` (throws ambiguity error with multiple conditions)\n",
    "        - `~` (not operator)\n",
    "        - `==` equality\n",
    "        - `!=` inequality\n",
    "        - `isin(list)` equivalent to `in` in SQL\n",
    "        - `>=`, `<=` relational\n",
    "        - `all(axis=0)` checks if all values across rows in each column are True\n",
    "        - `any(axis=1)` checks if atleast one value across columns in each row are True\n",
    "\n",
    "- `df.query(condition)` - condition can be involving columns or constants. Example - `(col1 > col2)` or `(col1 ==10)`\n",
    "- `df.filter()` - Arguments (optional but atleast 1 of first 3 required)\n",
    "    - `items` - list of column or row labels\n",
    "    - `like` - string for partial match (case sensitive)\n",
    "    - `regex` - string with regex to parse\n",
    "    - `axis` - row(0)/column(1) labels to filter \n",
    "- `df.isnull()` - checks if individual elements of dataframe are null (NaN/NaT)\n",
    "- `df.notnull()` - checks if individual elements of dataframe are not null (NaN/NaT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.fillna(value, inplace=True)` - Fills NaNs in all columns with value\n",
    "- `df.col.fillna(value, inplace=True)` - Fills NaNs in column `col` with value\n",
    "- `df[[cols]] = df[[cols]].fillna(value)` - Fills NaNs in columns `cols` with value\n",
    "\n",
    "\n",
    "\n",
    "- `df.dropna(axis=0, how='any', inplace=True)` - Drops rows with NaNs in any of the columns; For columns, use `axis=1`\n",
    "- `df.dropna(subset=[cols])` - Drops rows with NaNs in any of columns in `cols`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy like broadcasting behavior can be obtained by using following functions:\n",
    "\n",
    "- `df.add(row, axis=1)` - adds row to all rows of the dataframe df \n",
    "- `df.sub(column, axis=0)` - Subtracts column from all columns of the dataframe df\n",
    "- `df.mul()` - multiply\n",
    "- `df.div()` - divide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.groupby(['col1','col2']).func()` - func can be `sum`, `mean`, `count`, `unique`, `nunique`\n",
    "- `df.groupby(['col1','col2']).aggregate({'col3':['sum'], 'col4':['mean','count']})`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation and Joins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handy Utilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.shape` - Get the dimensions of the dataframe\n",
    "- `df.values` - Get the values as a numpy array\n",
    "- `df.head(x)` - Get first x rows of the dataframe\n",
    "- `df.tail(x)` - Get last x rows of the dataframe\n",
    "- `df.columns()` - Get column names\n",
    "- `df.info()` - High level metadata of columns and data\n",
    "- `df.nunique()` - Number of unique records in each column\n",
    "- `df.describe()` - High level statistical summary of numerical columns\n",
    "- `df.columns = df.columns.str.lower()` Converting column names to lower case\n",
    "- Pandas sees benifits of operations like aggregation, joins on sorted columns similar to tables in relational DBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
